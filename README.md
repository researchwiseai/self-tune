# Selfâ€‘Tune

> **Personalâ€‘data ingestion & fineâ€‘tuning platform - run locally, extend infinitely**

<!-- ![CI](https://github.com/researchwiseai/self-tune/actions/workflows/ci.yml/badge.svg) -->
[![License: Apacheâ€‘2.0](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](LICENSE)

---

## âœ¨Â Key Features

| Area | Highlights |
|------|------------|
| **Localâ€‘first** | Works entirely on your laptop with **BunÂ 1.2+**, **Temporalite**, and optional GPUs. |
| **Pluggable Connectors** | RSS, YouTube, LinkedIn, Git and moreâ€”dropâ€‘in modules based on the Airbyte spec. |
| **Deterministic Pipelines** | Temporal workflows + Nx hashing for resumable, cacheâ€‘friendly runs. |
| **Multiâ€‘runtime Kernels** | Swap heavy lifting between Python, Rust/Wasmtime or AssemblyScript WebAssembly. |
| **Fineâ€‘tuning Hub** | Train via OpenAI, local Huggingâ€¯Face PEFT, or your own Ollama serverâ€”all share one manifest. |
| **Humanâ€‘friendly UX** | Plainâ€‘English progress, actionable errors, visual dashboards & markdown Kanban board. |

---

## ğŸš€Â Quick Start

```bash
# 1.Â Clone repo
$ git clone https://github.com/yourâ€‘org/self-tune && cd self-tune

# 2.Â Install deps (Bun will infer)
$ bun install

# 3.Â Bootstrap Temporalite & Postgres (Docker Compose)
$ bun run dev:stack

# 4.Â Run first ingestion demo (example blog RSS)
$ bun cli ingest rss https://yourblog.com/rss.xml

# 5.Â Fineâ€‘tune with OpenAI GPTâ€‘3.5
$ bun cli train openai --model gpt-3.5-turbo --dataset datasets/demo.jsonl
```

> Need help?Â `bun cli --help` prints every command with examples.

---

## ğŸ—ï¸Â Architecture

```
           +-----------+       +---------------+
           | Connectors | ---> |  Preprocess   | --+-->  Vector Store
           +-----------+       +---------------+   |
                                                   |
 Git / RSS / Video / Audio               +---------v--------+
                                         |  Fineâ€‘tune Jobs  |
                                         +---------+--------+
                                                   |
                                          Model Registry (HF, OpenAI, Ollama)
```

Workflows are orchestrated by **Temporal** (or Temporalite locally) while Nx handles computationâ€‘caching and project graph.

---

## ğŸ“„Â Documentation

Full docsâ€”including API reference, tutorials and design decisionsâ€”live on **GitHubÂ Pages**:

> <https://yourâ€‘org.github.io/self-tune>

The detailed engineering roadmap is in [`development-plan.md`](./development-plan.md).

---

## ğŸ› ï¸Â Project Structure

```
apps/
  web/            # Dashboard (Vite + Bun)
packages/
  cli/            # Oclifâ€‘powered CLI
  ingestors/      # Source connectors
  preprocessors/  # Text, audio, video transforms
  workers/py/     # Python ML tasks (Whisper, PEFT)
  wasm/           # Optional WebAssembly kernels
.planning/        # Epics, stories, tasks, Kanban board
```

---

## ğŸ¤Â Contributing

We welcome PRs big & small!  Start by reading the [contrib guide](CONTRIBUTING.md) and picking an open Story in `.planning/stories/`.

* Run `bun test` before committing.
* Follow Conventional Commits (`feat:`, `fix:`...).
* All code is linted & formatted via ESLint + Prettier.
* Generate the Kanban board with `bun x backlog init .planning --out .planning/kanban`.

---

## ğŸ”Â License

Selfâ€‘Tune is **Apacheâ€‘2.0** licensed.  See [LICENSE](./LICENSE) for details.

---

Â©Â 2025Â Selfâ€‘TuneÂ Contributors
